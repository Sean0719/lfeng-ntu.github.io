<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Lei Feng</title>
    <base href="https://lfeng1995.github.io/publications.html">
</head>

<body>
<h1 style="padding-left: 0.5em">Lei Feng</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
	<div class="menu-item"><a href="publications.html">Publications</a></div>
	<!--<div class="menu-item"><a href="news.html">News</a></div>-->
    <!--<div class="menu-item"><a href="research.html">Research</a></div>-->
	<!--<div class="menu-item"><a href="group.html">Research Group</a></div>-->
	<div class="menu-item"><a href="services.html">Professional Services</a></div>
    <!--<div class="menu-item"><a href="teaching.html">Teaching</a></div>-->
    <div class="menu-item"><a href="codedata.html">Codes & Datasets</a></div>
    <!--<div class="menu-item"><a href="seminar.html">ML Seminar</a></div>-->
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Publications</h1><br>
<!-- 
<ul>
<li><p>Note that the copyrights of the listed papers belong to the corresponding publishers, so you are not allowed to distribute them without permission. These papers can only be used for research purpose. (本网页所列文章的版权归出版商所有，未经许可不得传播；所有文章仅供研究使用。)</p></li>
<li><p>IEEE/ACM Transactions系列文章为相关领域的世界顶级期刊，AAAI、IJCAI为人工智能领域国际顶级会议，CVPR、ICCV、ECCV为计算机视觉领域国际顶级会议，ICML、NeurIPS为机器学习领域国际顶级会议，KDD、ICDM为数据挖掘领域国际顶级会议。 </p></li>
</ul> -->
	
	<p>[ <a href="#2020">2020</a>,
         <a href="#2019">2019</a>,
         <a href="#2018">2018</a>]</p>
    

<!--     <div>
        <h2><hr>Preprints</h2>
        <ul>
            <li><p>
                T. Fang*, N. Lu*, G. Niu, and M. Sugiyama.<br>
                Rethinking importance weighting for deep learning under distribution shift.<br>
                [ <a href="http://arxiv.org/abs/2006.04662" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                S. Wu, X. Xia, T. Liu, B. Han, M. Gong, N. Wang, H. Liu, and G. Niu.<br>
                Class2Simi: A new perspective on learning with label noise.<br>
                [ <a href="http://arxiv.org/abs/2006.07831" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                X. Xia, T. Liu, B. Han, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
                Parts-dependent label noise: Towards instance-dependent label noise.<br>
                [ <a href="http://arxiv.org/abs/2006.07836" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                Y. Yao, T. Liu, B. Han, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
                Dual T: Reducing estimation error for transition matrix in label-noise learning.<br>
                [ <a href="http://arxiv.org/abs/2006.07805" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                S. Wu*, X. Xia*, T. Liu, B. Han, M. Gong, N. Wang, H. Liu, and G. Niu.<br>
                Multi-class classification from noisy-similarity-labeled data.<br>
                [ <a href="http://arxiv.org/abs/2002.06508" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                Y. Yao, T. Liu, B. Han, M. Gong, G. Niu, M. Sugiyama, and D. Tao.<br>
                Towards mixture proportion estimation without irreducibility.<br>
                [ <a href="http://arxiv.org/abs/2002.03673" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                A. Berthon, B. Han, G. Niu, T. Liu, and M. Sugiyama.<br>
                Confidence scores make instance-dependent label-noise learning possible.<br>
                [ <a href="https://arxiv.org/abs/2001.03772" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                J. Zhang*, B. Han*, G. Niu, T. Liu, and M. Sugiyama.<br>
                Where is the bottleneck of adversarial learning with unlabeled data?<br>
                [ <a href="http://arxiv.org/abs/1911.08696" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                A. Jacovi, G. Niu, Y. Goldberg, and M. Sugiyama.<br>
                Scalable evaluation and improvement of document set expansion via neural positive-unlabeled learning.<br>
                [ <a href="http://arxiv.org/abs/1910.13339" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                W. Xu, G. Niu, A. Hyvärinen, and M. Sugiyama.<br>
                Direction matters: On influence-preserving graph summarization and max-cut principle for directed graphs.<br>
                [ <a href="http://arxiv.org/abs/1907.09588" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                Y. Pan, W. Chen, G. Niu, I. W. Tsang, and M. Sugiyama.<br>
                Fast and robust rank aggregation against model misspecification.<br>
                [ <a href="http://arxiv.org/abs/1905.12341" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                F. Liu, J. Lu, B. Han, G. Niu, G. Zhang, and M. Sugiyama.<br>
                Butterfly: A panacea for all difficulties in wildly unsupervised domain adaptation.<br>
                [ <a href="http://arxiv.org/abs/1905.07720" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                C.-Y. Hsieh, M. Xu, G. Niu, H.-T. Lin, and M. Sugiyama.<br>
                A pseudo-label method for coarse-to-fine multi-label learning with limited supervision.<br>
                [ <a href="https://openreview.net/forum?id=rylVYjqHdN" target="_blank">OpenReview</a> ]
            </p></li>
            <li><p>
                M. Xu, B. Li, G. Niu, B. Han, and M. Sugiyama.<br>
                Revisiting sample selection approach to positive-unlabeled learning: Turning unlabeled data into positive rather than negative.<br>
                [ <a href="http://arxiv.org/abs/1901.10155" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                M. Kato, L. Xu, G. Niu, and M. Sugiyama.<br>
                Alternate estimation of a classifier and the class-prior from positive and unlabeled data.<br>
                [ <a href="http://arxiv.org/abs/1809.05710" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                M. Xu, G. Niu, B. Han, I. W. Tsang, Z.-H. Zhou, and M. Sugiyama.<br>
                Matrix co-completion for multi-label classification with missing features and labels.<br>
                [ <a href="http://arxiv.org/abs/1805.09156" target="_blank">arXiv</a> ]
            </p></li>
            <li><p>
                T. Sakai, G. Niu, and M. Sugiyama.<br>
                Information-theoretic representation learning for positive-unlabeled classification.<br>
                [ <a href="http://arxiv.org/abs/1710.05359" target="_blank">arXiv</a> ]
            </p></li>
        </ul>
    </div> -->
	
    <div>
        <h2><hr><a name="2020"></a>2020</h2>
        <ol>
            <li><p>
				<b>Lei Feng</b>, Jiaqi Lv, Bo Han, Miao Xu, Gang Niu, Xin Geng, Bo An, Masashi Sugiyama.<br> 
				Provably Consistent Partial-Label Learning.<br> 
				<i>Proceedings of the 34th Annual Conference on Neural Information Processing Systems (<b>NeurIPS'20</b>)</i>, accepted.<br>
                <!-- [ <a href="paper/chen_icml20.pdf" target="_blank">paper</a> ] -->
            </p></li>
			<li><p>
                <b>Lei Feng*</b>, Takuo Kaneko, Bo Han, Gang Niu, Bo An, Masashi Sugiyama.<br>
				Learning with Multiple Complementary Labels.<br> 
				<i>Proceedings of the 37th International Conference on Machine Learning (<b>ICML'20</b>)</i>, in press. (<sup>*</sup>Corresponding author, equal contribution).<br>
            </p></li>
			<li><p>
				Jiaqi Lv, Miao Xu, <b>Lei Feng</b>, Gang Niu, Xin Geng, Masashi Sugiyama.<br> 
				Progressive Identification of True Labels for Partial-Label Learning.<br>
				<i>Proceedings of the 37th International Conference on Machine Learning (<b>ICML'20</b>)</i>, in press.
            </p></li>
			<li><p>
				<b>Lei Feng</b>, Jun Huang, Senlin Shu, Bo An.<br>
				Regularized Matrix Factorization for Multi-Label Learning with Missing Labels.<br>
				<i>IEEE Transactions on Cybernetics (<b>IEEE-TCYB</b>)</i>, in press, DOI 10.1109/TCYB.2020.3016897, 2020.
            </p></li>
			<li><p>
				Jun Huang*, Linchuan Xu, Jing Wang, <b>Lei Feng*</b>, Kenji Yamanishi.<br> 
				Discovering Latent Class Labels for Multi-Label Learning.<br>
				<i>Proceedings of the 29th International Joint Conference on Artificial Intelligence (<b>IJCAI'20</b>)</i>, pp.3058-3064. (*Corresponding authors).
            </p></li>
			<li><p>
				<b>Lei Feng</b>, Senlin Shu, Zhuoyi Lin, Fengmao Lv, Li Li, Bo An.<br>
				Can Cross Entropy Loss be Robust to Label Noise?<br> 
				<i>Proceedings of the 29th International Joint Conference on Artificial Intelligence (<b>IJCAI'20</b>)</i>, pp.2206-2212.
            </p></li>
			<li><p>
				Hongxin Wei, <b>Lei Feng*</b>, Xiangyu Chen, Bo An.<br>
				Combating Noisy Labels by Agreement: A Joint Training Method with Co-Regularization.<br>
				<i>Proceedings of the 2020 IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR'20</b>)</i>, pp.13726-13735. (*Corresponding author).
            </p></li>			
        </ol>
    </div>
            <!-- 2019 -->

    <div>
        <h2><hr><a name="2019"></a>2019</h2>
        <ol>
            <li><p>
			<b>Lei Feng</b>, Bo An.<br> 
			Partial Label Learning with Self-Guided Retraining.<br> 
			<i>Proceedings of the 33rd AAAI Conference on Artificial Intelligence (<b>AAAI'19</b>)</i>, pp.3542-3549.
            </p></li>
            <li><p>
			<b>Lei Feng</b>, Bo An, Shuo He.<br>
			Collaboration based Multi-Label Learning.<br> 
			<i>Proceedings of the 33rd AAAI Conference on Artificial Intelligence (<b>AAAI'19</b>)</i>, pp.3550-3557.
            </p></li>
            <li><p>
			<b>Lei Feng</b>, Bo An.<br>
			Partial Label Learning by Semantic Difference Maximization.<br>
			<i>Proceedings of the 28th International Joint Conference on Artificial Intelligence (<b>IJCAI'19</b>)</i>, pp.2294-2300.
            </p></li>
        </ol>
    </div>

    <div>
        <h2><hr><a name="2018"></a>2018</h2>
        <ol>
            <li><p>
			<b>Lei Feng</b>, Bo An.<br> 
			Leveraging Latent Label Distributions for Partial Label Learning.<br>
			<i>Proceedings of the 27th International Joint Conference on Artificial Intelligence (<b>IJCAI'18</b>)</i>, pp.2107-2113.
            </p></li>
            <li><p>
			Shuo He, <b>Lei Feng</b>, Li Li.<br>
			Estimating Latent Relative Labeling Importances for Multi-Label Learning.<br> 
			<i>Proceedings of the 2018 IEEE International Conference on Data Mining (<b>ICDM'18</b>)</i>, pp.1013-1018.
            </p></li>
        </ol>
    </div>

<!--
    <div>
        <h2><hr><a name="2017"></a>2017</h2>
        <ol>
            <li><p>
			Yantao Li, Fengtao Xue, Lei Feng, Zehui Qu. A Driving Behavior Detection System based on a Smartphone's Built-in Sensor. International Journal of Communication Systems, 30(8):1-13, 2017.
            </p></li>
        </ol>
    </div> -->

<!--
    <div>
        <h2><hr><a name="2016"></a>2016</h2>
        <ol>
            <li><p>
			Guoxian Yu, Lei Feng, Guangjun Yao, Jun Wang. Semi-Supervised Classfication using Multiple Clusterings. Pattern Recognition and Image Analysis, 26(4):681-687, 2016.
            </p></li>
        </ol>
    </div> -->

<!-- 2015 -->
<!--
    <div>
        <h2><hr><a name="2015"></a>2015</h2>
        <ol>
            <li><p>
			Lei Feng, Guoxian Yu. Semi-Supervised Classfication Based on Mixture Graph. Algorithms, 8(4):1021-1034, 2015.
            </p></li>
        </ol>
    </div> -->



</td>
</tr>
</table>
</body>
</html>
